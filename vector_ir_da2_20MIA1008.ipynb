{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### SANJAY KUMAR\r\n",
    "### 20MIA1008\r\n",
    "### IRO-DA2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import nltk\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.metrics.pairwise import cosine_similarity\r\n",
    "from sklearn.metrics import jaccard_score\r\n",
    "\r\n",
    "nltk.download('punkt')\r\n",
    "nltk.download('stopwords')\r\n",
    "\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "\r\n",
    "# Define the set of documents\r\n",
    "docs = [\"Every year Maha Shivratri is celebrated with a lot of pomp and grandeur. It is considered to be a very special time of the year since millions of people celebrate this momentous occasion with a lot of fervour and glee.\",\r\n",
    "        \"Lord Shiva devotees celebrate this occasion with a lot of grandness. It is accompanied by folk dances, songs, prayers, chants, mantras etc. This year, the beautiful occasion of Maha Shivratri will be celebrated on February 18.\",\r\n",
    "        \"People keep a fast on this Maha shivratri, stay awake at night and pray to the lord for blessings, happiness, hope and prosperity. This festival holds a lot of significance and is considered to be one of the most important festivals in India.\",\r\n",
    "        \"The festival of Maha Shivratri will be celebrated on February 18 and is a very auspicious festival. This Hindu festival celebrates the power of Lord Shiva. Lord Shiva protects his devotees from negative and evil spirits. He is the epitome of powerful and auspicious energy.\"]\r\n",
    "\r\n",
    "# Define the query\r\n",
    "query = \"Maha Shivratri will be celebrated on February 18.\"\r\n",
    "\r\n",
    "# Define stop words\r\n",
    "stop_words = set(stopwords.words('english'))\r\n",
    "\r\n",
    "# Tokenize and remove stop words from each document and the query\r\n",
    "docs_tokens = []\r\n",
    "for doc in docs:\r\n",
    "    tokens = word_tokenize(doc.lower())\r\n",
    "    tokens = [token for token in tokens if token.isalpha()]\r\n",
    "    tokens = [token for token in tokens if token not in stop_words]\r\n",
    "    docs_tokens.append(tokens)\r\n",
    "\r\n",
    "query_tokens = word_tokenize(query.lower())\r\n",
    "query_tokens = [token for token in query_tokens if token.isalpha()]\r\n",
    "query_tokens = [token for token in query_tokens if token not in stop_words]\r\n",
    "\r\n",
    "# Convert the documents and the query into vectors of TF-IDF values\r\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False)\r\n",
    "vectorizer.fit(docs_tokens)\r\n",
    "doc_vectors = vectorizer.transform(docs_tokens)\r\n",
    "query_vector = vectorizer.transform([query_tokens])\r\n",
    "\r\n",
    "# Compute cosine similarity score between the query and all documents\r\n",
    "cosine_sim = cosine_similarity(query_vector, doc_vectors)\r\n",
    "\r\n",
    "# Compute Jaccardian similarity score between the query and all documents\r\n",
    "query_tf = {}\r\n",
    "for term in query_tokens:\r\n",
    "    if term in query_tf:\r\n",
    "        query_tf[term] += 1\r\n",
    "    else:\r\n",
    "        query_tf[term] = 1\r\n",
    "        \r\n",
    "query_tfidf = {}\r\n",
    "for term in query_tf:\r\n",
    "    if term in vectorizer.vocabulary_:\r\n",
    "        query_tfidf[term] = query_tf[term] * vectorizer.idf_[vectorizer.vocabulary_[term]]\r\n",
    "        \r\n",
    "jaccardian_scores = []\r\n",
    "for doc_tf in doc_vectors.toarray():\r\n",
    "    doc_tfidf = {}\r\n",
    "    for term in vectorizer.vocabulary_:\r\n",
    "        if doc_tf[vectorizer.vocabulary_[term]] > 0:\r\n",
    "            doc_tfidf[term] = doc_tf[vectorizer.vocabulary_[term]] * vectorizer.idf_[vectorizer.vocabulary_[term]]\r\n",
    "        \r\n",
    "    intersection = set(doc_tfidf.keys()) & set(query_tfidf.keys())\r\n",
    "    union = set(doc_tfidf.keys()) | set(query_tfidf.keys())\r\n",
    "    jaccardian_scores.append(len(intersection)/ len(union))\r\n",
    "\r\n",
    "# Print the results\r\n",
    "print(\"Cosine similarity score:\")\r\n",
    "for i in range(len(docs)):\r\n",
    "    print(f\"Similarity between query and doc {i}: {cosine_sim[0][i]:.2f}\")\r\n",
    "        \r\n",
    "print(\"\\nJaccardian similarity score:\")\r\n",
    "for i in range(len(docs)):\r\n",
    "    print(f\"Similarity between query and doc {i}: {jaccardian_scores[i]:.2f}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cosine similarity score:\n",
      "Similarity between query and doc 0: 0.18\n",
      "Similarity between query and doc 1: 0.30\n",
      "Similarity between query and doc 2: 0.10\n",
      "Similarity between query and doc 3: 0.25\n",
      "\n",
      "Jaccardian similarity score:\n",
      "Similarity between query and doc 0: 0.15\n",
      "Similarity between query and doc 1: 0.19\n",
      "Similarity between query and doc 2: 0.08\n",
      "Similarity between query and doc 3: 0.21\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\skp68\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\skp68\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\skp68\\anaconda31\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "interpreter": {
   "hash": "4dce5c4c6a5efda62ca28ab768c355f1b97b6bef8cd78648c771c922a70a0eeb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}